= FIRDS Project
Mikael Andersson Wigander <mikael.andersson.wigander@pm.me>
1.0, July 29, 2022: Enterprise Integration Pattern demo
:icons: font
:source-highlighter: coderay
:coderay-linenums-mode: table
:source-indent: 0

[.lead]
This project uses Quarkus, the Supersonic Subatomic Java Framework.

If you want to learn more about Quarkus, please visit its website: https://quarkus.io/ .

== FIRDS

*FIRDS* - _Financial Instruments Reference Data System_ - a system where we can lookup information and metadata on financial instruments such as Equities, Bonds and so on.

This application will demonstrate some useful and common patterns used in *Enterprise Integration*.

Specifically it demonstrates:

* consuming services
* producing output
* marshall/unmarshall and parsing data formats
* enrich content
* persisting endpoints
* streaming
* parallel processing

We will illustrate a scenario where we need to persist data derived from the *ESMA FIRDS* source in a database. The data is not fully complete so we need to enrich it. First we need to insert all instruments in our database and then use the data from the *ANNA* service to further enrich the data with the code from the *Issuer* of the instrument. Then we finalise the enrichment by selecting records from the database and query an online service, *GLEIF*, to set the Country on the data.

So we are creating many records from FIRDS in our database, lacking Issuer and country, which we need to enrich from other sources.

The application will demonstrate a process where we query a `REST` service using a query to determine what we can download. +
The reply, in `XML`, will be links we parse and use to continue the actual downloadable content.

[,xml,linenums,indent="0"]
.https.xml
----
<result name="response" numFound="3632" start="0">
        <doc>
            <str name="checksum">f7f1f7ce35f9831403cd593b9a06901a</str>
            <str name="download_link">http://firds.esma.europa.eu/firds/DLTINS_20201113_01of02.zip</str> <!--.-->
            <date name="publication_date">2020-11-13T00:00:00Z</date>
            <str name="published_instrument_file_id">43428</str>
            <str name="_root_">43428</str>
            <str name="id">43428</str>
            <str name="file_name">DLTINS_20201113_01of02.zip</str>
            <str name="file_type">DLTINS</str>
            <long name="_version_">1749431080840069145</long>
            <date name="timestamp">2022-11-14T00:58:10.120Z</date></doc>
        <doc>
            <str name="checksum">e4b695fe27ade6de5bccb9d605400268</str>
            <str name="download_link">http://firds.esma.europa.eu/firds/DLTINS_20201113_02of02.zip</str>
            <date name="publication_date">2020-11-13T00:00:00Z</date>
            <str name="published_instrument_file_id">43429</str>
            <str name="_root_">43429</str>
            <str name="id">43429</str>
            <str name="file_name">DLTINS_20201113_02of02.zip</str>
            <str name="file_type">DLTINS</str>
            <long name="_version_">1749431080840069146</long>
            <date name="timestamp">2022-11-14T00:58:10.120Z</date></doc>
...
</result>
----
<.> Link to parse for a downloadable file

The `zip` files produced by the service is stored on disk as is.

A *File* route will unmarshal these `zip` files _(unzip them)_ and read the content. Content is an `XML` file. This file contains `1->M` instrument data records.

For each instrument record we will parse the `XML` and generate an `SQL` to either `INSERT` or `DELETE` in the database we have connected to. Database is of type *PostgreSQL*. +
This will store the base data we need to further enrich each record. The data is not 100% fulfilled so we need to query some more services, *ANNA* and *GLEIF*.

*ANNA* is a service where we download data on financial instruments using the same process as before, query a service using some parameters, receive an `HTML` file with download links on, parse that and download a `.zip` file. +
This `.zip` file contains a `.csv` file that we need to parse and use to enrich data in our database.

[source,csv,linenums]
.anna.csv
----
LEI,ISIN
724500V6UOK62XEZ2L78,NLEN03247298 <.>
529900W18LQJJN6SJ336,DE000SN4ESX0
724500V6UOK62XEZ2L78,NLENX7751979
724500V6UOK62XEZ2L78,NLICE3689953
----
<.> Rows to parse, Issuer ID (LEI) and ISIN (Instrument ID)

Furthermore we still need to fetch more data for enrichment so we query the database for records and use each record to query another `REST` api, `GLEIF`. +
This service is a regular `REST` api where we query using _normal_ `HTTP` calls and receive a `JSON` structure. However this service has restrictions in the amount of calls that can be made. We need to make our calls restricted to the terms they provide, throttling is used to control the flow, so we won't DDOS them.

We query based on data from our database and enrich using the parsed country code.

[source,json,linenums,line-comment=%]
.gleif.json
----
{
  "data": [
    {
      "type": "lei-records",
      "id": "98450057F0051A6CCA56",
      "attributes": {
        "lei": "98450057F0051A6CCA56",
        "entity": {
          "legalName": {
            "name": "BRANNKASSESTIFTELSEN MIDT-BUSKERUD",
            "language": "no"
          },
          "otherNames": [],
          "transliteratedOtherNames": [],
          "legalAddress": {
            "language": "no",
            "addressLines": [
              "Vikersundgata 17"
            ],
            "addressNumber": null,
            "addressNumberWithinBuilding": null,
            "mailRouting": null,
            "city": "VIKERSUND",
            "region": null,
            "country": "NO", %<.>
            "postalCode": "3370"
          },
          "headquartersAddress": {
            "language": "no",
            "addressLines": [
              "Vikersundgata 17"
            ],
            "addressNumber": null,
            "addressNumberWithinBuilding": null,
            "mailRouting": null,
            "city": "VIKERSUND",
            "region": null,
            "country": "NO",
            "postalCode": "3370"
          }
      },
      "relationships": {
        "managing-lou": {
          "links": {
            "related": "https:\/\/api.gleif.org\/api\/v1\/lei-records\/98450057F0051A6CCA56\/managing-lou"
          }
        }
      },
      "links": {
        "self": "https:\/\/api.gleif.org\/api\/v1\/lei-records\/98450057F0051A6CCA56"
      }
    }
  ]
}
----
<.> Entry we need to parse

Using `jsonpath` we can extract the following given the reply has 15 entries:

[,json]
----
[
  "NO",
  "NO",
  "SE",
  "SE",
  "DK",
  "US",
  "US",
  "DK",
  "US",
  "US",
  "US",
  "IN",
  "DK",
  "DE",
  "EE"
]
----

These countries is the used to finalise the enrichment of the records.

<<<
Some useful links:

* https://www.enterpriseintegrationpatterns.com/index.html[Enterprise Integration Patterns]
* https://camel.apache.org[Apache Camel]

== Running the application in dev mode

You can run your application in dev mode that enables live coding using:

[source,shell script]
----
./mvnw compile quarkus:dev

----

NOTE:  Quarkus now ships with a Dev UI, which is available in dev mode only at http://localhost:8080/q/dev/.


== Packaging and running the application

The application can be packaged using:

[source,shell script]
----
./mvnw package
----

It produces the `quarkus-run.jar` file in the `target/quarkus-app/` directory.
Be aware that it’s not an _über-jar_ as the dependencies are copied into the `target/quarkus-app/lib/` directory.

The application is now runnable using `java -jar target/quarkus-app/quarkus-run.jar`.

If you want to build an _über-jar_, execute the following command:

[source,shell script]
----
./mvnw package -Dquarkus.package.type=uber-jar
----

The application, packaged as an _über-jar_, is now runnable using `java -jar target/*-runner.jar`.

== Creating a native executable

You can create a native executable using: 

[source,shell script]
----
./mvnw package -Pnative
----

Or, if you don't have GraalVM installed, you can run the native executable build in a container using: 

[source,shell script]
----
*./mvnw* package -Pnative -Dquarkus.native.container-build=true
----

You can then execute your native executable with: `./target/firds-1.0.0-SNAPSHOT-runner`

If you want to learn more about building native executables, please consult https://quarkus.io/guides/maven-tooling.

== Related Guides

* Camel Core (https://camel.apache.org/camel-quarkus/latest/reference/extensions/core.html[guide]): Camel core functionality and basic Camel languages: Constant, ExchangeProperty, Header, Ref, Simple and Tokenize
* Camel Quartz (https://camel.apache.org/camel-quarkus/latest/reference/extensions/quartz.html[guide]): Schedule sending of messages using the Quartz 2.x scheduler
* Camel Direct (https://camel.apache.org/camel-quarkus/latest/reference/extensions/direct.html[guide]): Call another endpoint from the same Camel Context synchronously
* Camel Data Format (https://camel.apache.org/camel-quarkus/latest/reference/extensions/dataformat.html[guide]): Use a Camel Data Format as a regular Camel Component
* YAML Configuration (https://quarkus.io/guides/config#yaml[guide]): Use YAML to configure your Quarkus application
* Camel Jackson (https://camel.apache.org/camel-quarkus/latest/reference/extensions/jackson.html[guide]): Marshal POJOs to JSON and back using Jackson
* Camel Mock (https://camel.apache.org/camel-quarkus/latest/reference/extensions/mock.html[guide]): Test routes and mediation rules using mocks
* Camel Bean (https://camel.apache.org/camel-quarkus/latest/reference/extensions/bean.html[guide]): Invoke methods of Java beans
* Camel REST OpenApi (https://camel.apache.org/camel-quarkus/latest/reference/extensions/rest-openapi.html[guide]): Configure REST producers based on an OpenAPI specification document delegating to a component implementing the RestProducerFactory interface
* Camel XPath (https://camel.apache.org/camel-quarkus/latest/reference/extensions/xpath.html[guide]): Evaluates an XPath expression against an XML payload
* Camel HTTP (https://camel.apache.org/camel-quarkus/latest/reference/extensions/http.html[guide]): Send requests to external HTTP servers using Apache HTTP Client 4.x
* Camel JSON Path (https://camel.apache.org/camel-quarkus/latest/reference/extensions/jsonpath.html[guide]): Evaluate a JSONPath expression against a JSON message body
* Camel Log (https://camel.apache.org/camel-quarkus/latest/reference/extensions/log.html[guide]): Log messages to the underlying logging mechanism
* Camel SEDA (https://camel.apache.org/camel-quarkus/latest/reference/extensions/seda.html[guide]): Asynchronously call another endpoint from any Camel Context in the same JVM
* Camel JacksonXML (https://camel.apache.org/camel-quarkus/latest/reference/extensions/jacksonxml.html[guide]): Unmarshal an XML payloads to POJOs and back using XMLMapper extension of Jackson
* SmallRye Reactive Messaging (https://quarkus.io/guides/reactive-messaging[guide]): Produce and consume messages and implement event driven and data streaming applications
* Camel ActiveMQ (https://camel.apache.org/camel-quarkus/latest/reference/extensions/activemq.html[guide]): Send messages to (or consume from) Apache ActiveMQ. This component extends the Camel JMS component
* Reactive PostgreSQL client (https://quarkus.io/guides/reactive-sql-clients[guide]): Connect to the PostgreSQL database using the reactive pattern
* Camel JDBC (https://camel.apache.org/camel-quarkus/latest/reference/extensions/jdbc.html[guide]): Access databases through SQL and JDBC
* Camel Rest (https://camel.apache.org/camel-quarkus/latest/reference/extensions/rest.html[guide]): Expose REST services and their OpenAPI Specification or call external REST services

== Provided Code

=== YAML Config

Configure your application with YAML

https://quarkus.io/guides/config-reference#configuration-examples[Related guide section…]

The Quarkus application configuration is located in `src/main/resources/application.yml`.